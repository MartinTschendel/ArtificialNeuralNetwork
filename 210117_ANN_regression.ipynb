{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"colab":{"name":"210117_ANN_regression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"95XyGuqQ36ZS","executionInfo":{"status":"ok","timestamp":1611012293056,"user_tz":-480,"elapsed":1082,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#import libraries\r\n","import numpy as np\r\n","import pandas as pd\r\n","import tensorflow as tf"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q3wP2XZG4XIJ","executionInfo":{"status":"ok","timestamp":1611012296339,"user_tz":-480,"elapsed":4357,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#import dataset\r\n","dataset = pd.read_excel('dataset.xlsx')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, -1].values"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x46s5S3e54JH","executionInfo":{"status":"ok","timestamp":1611012296340,"user_tz":-480,"elapsed":4352,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}},"outputId":"1e70874f-fb80-452d-ae1a-e74fe23e8030"},"source":["print(X)\r\n","print(y)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["[[  14.96   41.76 1024.07   73.17]\n"," [  25.18   62.96 1020.04   59.08]\n"," [   5.11   39.4  1012.16   92.14]\n"," ...\n"," [  31.32   74.33 1012.92   36.48]\n"," [  24.48   69.45 1013.86   62.39]\n"," [  21.6    62.52 1017.23   67.87]]\n","[463.26 444.37 488.56 ... 429.57 435.74 453.28]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZKnFTOa959WQ","executionInfo":{"status":"ok","timestamp":1611012296341,"user_tz":-480,"elapsed":4347,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#split dataset in train and test set\r\n","from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"execution_count":58,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5Zc9Nm09jZU","executionInfo":{"status":"ok","timestamp":1611012296341,"user_tz":-480,"elapsed":4341,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#initialize the ANN as a sequence of layers\r\n","#'ann' is an object of the 'Sequential' class\r\n","ann = tf.keras.models.Sequential()"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qi4oL04RjfX_","executionInfo":{"status":"ok","timestamp":1611012296342,"user_tz":-480,"elapsed":4336,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#add input layer\r\n","#'Dense' stands for full connection between input and first hidden layer\r\n","#'units' are neurons in first hidden layer\r\n","#'relu' stands for rectifier function\r\n","ann.add(tf.keras.layers.Dense(units=5, activation='relu'))\r\n","#add second hidden layer\r\n","ann.add(tf.keras.layers.Dense(units=5, activation='relu'))"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"EacW_Pj-l0Iu","executionInfo":{"status":"ok","timestamp":1611012296343,"user_tz":-480,"elapsed":4331,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#add output layer\r\n","#for regression problems, no activation function required\r\n","ann.add(tf.keras.layers.Dense(units=1))"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"IneHcwynojHl","executionInfo":{"status":"ok","timestamp":1611012296345,"user_tz":-480,"elapsed":4325,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#compiling the ANN\r\n","#that means: connect to ANN, optimizer and loss function\r\n","#optimizer: stochastic gradient descent tool (to adjust weights)\r\n","#loss function: gets difference between actual and predicted value\r\n","ann.compile(optimizer='adam', loss='mean_squared_error')"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MdoYwJewqQ0N","executionInfo":{"status":"ok","timestamp":1611012319982,"user_tz":-480,"elapsed":27954,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}},"outputId":"f8dbf257-7931-4ab2-cc35-21eaeff190fe"},"source":["#train ANN on training set\r\n","ann.fit(X_train, y_train, batch_size=32, epochs=100)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","240/240 [==============================] - 1s 921us/step - loss: 162865.9179\n","Epoch 2/100\n","240/240 [==============================] - 0s 904us/step - loss: 8165.2155\n","Epoch 3/100\n","240/240 [==============================] - 0s 908us/step - loss: 406.9686\n","Epoch 4/100\n","240/240 [==============================] - 0s 929us/step - loss: 376.1240\n","Epoch 5/100\n","240/240 [==============================] - 0s 952us/step - loss: 329.7097\n","Epoch 6/100\n","240/240 [==============================] - 0s 953us/step - loss: 277.4702\n","Epoch 7/100\n","240/240 [==============================] - 0s 934us/step - loss: 241.3462\n","Epoch 8/100\n","240/240 [==============================] - 0s 983us/step - loss: 190.2795\n","Epoch 9/100\n","240/240 [==============================] - 0s 998us/step - loss: 164.8440\n","Epoch 10/100\n","240/240 [==============================] - 0s 991us/step - loss: 128.5113\n","Epoch 11/100\n","240/240 [==============================] - 0s 938us/step - loss: 107.7498\n","Epoch 12/100\n","240/240 [==============================] - 0s 960us/step - loss: 89.8141\n","Epoch 13/100\n","240/240 [==============================] - 0s 979us/step - loss: 72.9398\n","Epoch 14/100\n","240/240 [==============================] - 0s 949us/step - loss: 60.0494\n","Epoch 15/100\n","240/240 [==============================] - 0s 985us/step - loss: 50.4538\n","Epoch 16/100\n","240/240 [==============================] - 0s 924us/step - loss: 41.7202\n","Epoch 17/100\n","240/240 [==============================] - 0s 1ms/step - loss: 38.2561\n","Epoch 18/100\n","240/240 [==============================] - 0s 923us/step - loss: 34.9803\n","Epoch 19/100\n","240/240 [==============================] - 0s 954us/step - loss: 33.7247\n","Epoch 20/100\n","240/240 [==============================] - 0s 957us/step - loss: 31.6767\n","Epoch 21/100\n","240/240 [==============================] - 0s 987us/step - loss: 30.2802\n","Epoch 22/100\n","240/240 [==============================] - 0s 959us/step - loss: 29.9540\n","Epoch 23/100\n","240/240 [==============================] - 0s 994us/step - loss: 28.6143\n","Epoch 24/100\n","240/240 [==============================] - 0s 940us/step - loss: 29.4332\n","Epoch 25/100\n","240/240 [==============================] - 0s 909us/step - loss: 28.5611\n","Epoch 26/100\n","240/240 [==============================] - 0s 956us/step - loss: 28.7657\n","Epoch 27/100\n","240/240 [==============================] - 0s 956us/step - loss: 31.2690\n","Epoch 28/100\n","240/240 [==============================] - 0s 970us/step - loss: 28.0299\n","Epoch 29/100\n","240/240 [==============================] - 0s 952us/step - loss: 28.5725\n","Epoch 30/100\n","240/240 [==============================] - 0s 979us/step - loss: 27.6327\n","Epoch 31/100\n","240/240 [==============================] - 0s 946us/step - loss: 25.8989\n","Epoch 32/100\n","240/240 [==============================] - 0s 990us/step - loss: 27.6582\n","Epoch 33/100\n","240/240 [==============================] - 0s 940us/step - loss: 27.4123\n","Epoch 34/100\n","240/240 [==============================] - 0s 995us/step - loss: 26.7917\n","Epoch 35/100\n","240/240 [==============================] - 0s 969us/step - loss: 27.7077\n","Epoch 36/100\n","240/240 [==============================] - 0s 951us/step - loss: 26.8520\n","Epoch 37/100\n","240/240 [==============================] - 0s 930us/step - loss: 27.0938\n","Epoch 38/100\n","240/240 [==============================] - 0s 969us/step - loss: 26.1752\n","Epoch 39/100\n","240/240 [==============================] - 0s 979us/step - loss: 29.0421\n","Epoch 40/100\n","240/240 [==============================] - 0s 943us/step - loss: 26.7809\n","Epoch 41/100\n","240/240 [==============================] - 0s 983us/step - loss: 28.2202\n","Epoch 42/100\n","240/240 [==============================] - 0s 957us/step - loss: 25.9125\n","Epoch 43/100\n","240/240 [==============================] - 0s 1ms/step - loss: 26.5453\n","Epoch 44/100\n","240/240 [==============================] - 0s 982us/step - loss: 28.0753\n","Epoch 45/100\n","240/240 [==============================] - 0s 996us/step - loss: 27.5820\n","Epoch 46/100\n","240/240 [==============================] - 0s 956us/step - loss: 29.2561\n","Epoch 47/100\n","240/240 [==============================] - 0s 981us/step - loss: 27.1981\n","Epoch 48/100\n","240/240 [==============================] - 0s 985us/step - loss: 27.2268\n","Epoch 49/100\n","240/240 [==============================] - 0s 941us/step - loss: 25.9937\n","Epoch 50/100\n","240/240 [==============================] - 0s 918us/step - loss: 27.1928\n","Epoch 51/100\n","240/240 [==============================] - 0s 969us/step - loss: 28.1065\n","Epoch 52/100\n","240/240 [==============================] - 0s 982us/step - loss: 26.7927\n","Epoch 53/100\n","240/240 [==============================] - 0s 959us/step - loss: 26.7602\n","Epoch 54/100\n","240/240 [==============================] - 0s 991us/step - loss: 27.5748\n","Epoch 55/100\n","240/240 [==============================] - 0s 947us/step - loss: 27.5150\n","Epoch 56/100\n","240/240 [==============================] - 0s 999us/step - loss: 27.0771\n","Epoch 57/100\n","240/240 [==============================] - 0s 974us/step - loss: 28.7485\n","Epoch 58/100\n","240/240 [==============================] - 0s 985us/step - loss: 25.9094\n","Epoch 59/100\n","240/240 [==============================] - 0s 963us/step - loss: 25.5848\n","Epoch 60/100\n","240/240 [==============================] - 0s 1ms/step - loss: 29.0393\n","Epoch 61/100\n","240/240 [==============================] - 0s 965us/step - loss: 27.8301\n","Epoch 62/100\n","240/240 [==============================] - 0s 971us/step - loss: 29.3672\n","Epoch 63/100\n","240/240 [==============================] - 0s 943us/step - loss: 28.1368\n","Epoch 64/100\n","240/240 [==============================] - 0s 999us/step - loss: 26.2423\n","Epoch 65/100\n","240/240 [==============================] - 0s 980us/step - loss: 27.0441\n","Epoch 66/100\n","240/240 [==============================] - 0s 937us/step - loss: 27.8244\n","Epoch 67/100\n","240/240 [==============================] - 0s 979us/step - loss: 26.3283\n","Epoch 68/100\n","240/240 [==============================] - 0s 987us/step - loss: 27.2908\n","Epoch 69/100\n","240/240 [==============================] - 0s 958us/step - loss: 28.7893\n","Epoch 70/100\n","240/240 [==============================] - 0s 987us/step - loss: 27.0660\n","Epoch 71/100\n","240/240 [==============================] - 0s 998us/step - loss: 28.4528\n","Epoch 72/100\n","240/240 [==============================] - 0s 946us/step - loss: 26.2962\n","Epoch 73/100\n","240/240 [==============================] - 0s 1ms/step - loss: 25.7992\n","Epoch 74/100\n","240/240 [==============================] - 0s 926us/step - loss: 28.2652\n","Epoch 75/100\n","240/240 [==============================] - 0s 982us/step - loss: 28.7120\n","Epoch 76/100\n","240/240 [==============================] - 0s 923us/step - loss: 26.1375\n","Epoch 77/100\n","240/240 [==============================] - 0s 1ms/step - loss: 27.0016\n","Epoch 78/100\n","240/240 [==============================] - 0s 961us/step - loss: 26.1342\n","Epoch 79/100\n","240/240 [==============================] - 0s 930us/step - loss: 27.3551\n","Epoch 80/100\n","240/240 [==============================] - 0s 989us/step - loss: 27.9130\n","Epoch 81/100\n","240/240 [==============================] - 0s 961us/step - loss: 27.1537\n","Epoch 82/100\n","240/240 [==============================] - 0s 949us/step - loss: 25.5362\n","Epoch 83/100\n","240/240 [==============================] - 0s 973us/step - loss: 27.8073\n","Epoch 84/100\n","240/240 [==============================] - 0s 960us/step - loss: 27.9921\n","Epoch 85/100\n","240/240 [==============================] - 0s 925us/step - loss: 25.9641\n","Epoch 86/100\n","240/240 [==============================] - 0s 968us/step - loss: 27.1321\n","Epoch 87/100\n","240/240 [==============================] - 0s 943us/step - loss: 27.2468\n","Epoch 88/100\n","240/240 [==============================] - 0s 1ms/step - loss: 26.9560\n","Epoch 89/100\n","240/240 [==============================] - 0s 937us/step - loss: 27.1717\n","Epoch 90/100\n","240/240 [==============================] - 0s 1ms/step - loss: 28.7307\n","Epoch 91/100\n","240/240 [==============================] - 0s 948us/step - loss: 26.8627\n","Epoch 92/100\n","240/240 [==============================] - 0s 979us/step - loss: 26.8769\n","Epoch 93/100\n","240/240 [==============================] - 0s 920us/step - loss: 26.9059\n","Epoch 94/100\n","240/240 [==============================] - 0s 999us/step - loss: 28.0975\n","Epoch 95/100\n","240/240 [==============================] - 0s 964us/step - loss: 27.5274\n","Epoch 96/100\n","240/240 [==============================] - 0s 998us/step - loss: 27.7988\n","Epoch 97/100\n","240/240 [==============================] - 0s 929us/step - loss: 27.2781\n","Epoch 98/100\n","240/240 [==============================] - 0s 979us/step - loss: 25.9995\n","Epoch 99/100\n","240/240 [==============================] - 0s 1ms/step - loss: 27.7658\n","Epoch 100/100\n","240/240 [==============================] - 0s 960us/step - loss: 26.2266\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f94ed5726d8>"]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"mpvzEGgjunW3","executionInfo":{"status":"ok","timestamp":1611012319983,"user_tz":-480,"elapsed":27942,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":["#predict results of test set\r\n","y_pred = ann.predict(X_test)"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzPfeHawux67","executionInfo":{"status":"ok","timestamp":1611012319983,"user_tz":-480,"elapsed":27934,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}},"outputId":"cfa773bd-2b06-47ac-c7dc-26c8765c171f"},"source":["y_pred[:5]"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[432.7 ],\n","       [463.78],\n","       [467.3 ],\n","       [450.36],\n","       [461.58]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"kDI-CnNIu0fk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611012319984,"user_tz":-480,"elapsed":27924,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}},"outputId":"91d26d82-190a-46f5-c641-0cffb16f5a5b"},"source":["#compare predicted values with real values\r\n","#'precision' means digits after the comma\r\n","np.set_printoptions(precision=2)\r\n","\r\n","#we have to transform the horizontal vectors \r\n","#'y_pred' and 'y_test' into a vertical ones\r\n","#this is done with reshape\r\n","\r\n","#then we want to put the 2 vectors next to each other\r\n","#done with concatenate\r\n","#concatenate has 2 arguments\r\n","#First argument: the 2 vectors y_pred & y_test\r\n","#Second argument: a '1', that stands for vertical concatenation\r\n","#(if we want horizontal concatenation: it should be 0)\r\n","conc_vec = np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)), 1)\r\n","conc_vec "],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[432.7 , 431.23],\n","       [463.78, 460.01],\n","       [467.3 , 461.14],\n","       ...,\n","       [474.53, 473.26],\n","       [441.21, 438.  ],\n","       [460.47, 463.28]])"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Q1FTofQyjmj","executionInfo":{"status":"ok","timestamp":1611012319985,"user_tz":-480,"elapsed":27917,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}},"outputId":"db3af1b3-2421-469d-cf1a-878196dfcbd8"},"source":["#get mean squared error from predicted values\r\n","from sklearn.metrics import mean_squared_error\r\n","mean_squared_error(y_test, y_pred)"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26.544347164386934"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"id":"urT0FYj-yxrn","executionInfo":{"status":"ok","timestamp":1611012319986,"user_tz":-480,"elapsed":27911,"user":{"displayName":"Martin Martin Tschendel","photoUrl":"","userId":"04898717809093403221"}}},"source":[""],"execution_count":67,"outputs":[]}]}